{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Surfcast.com</h1>\n",
    "<h3>A Goodfellow Analytics Creation</h3>\n",
    "<h5>In partnership with Griffin Global</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "# Reset Notebook\n",
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib import request\n",
    "import requests\n",
    "from urllib.request import urlopen\n",
    "from datetime import datetime, timedelta\n",
    "from pytz import timezone\n",
    "import pytz\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dateutil import parser\n",
    "from dateutil import tz\n",
    "import scipy.interpolate\n",
    "import os\n",
    "from sqlalchemy import create_engine # database connection\n",
    "\n",
    "# Matplotlib inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Hide ipython notebook warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Step 1</h1>\n",
    "<h3>Get HTML Database as List of Files</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set URL path to NOAA 'gridded fields' database\n",
    "url = 'http://www.glerl.noaa.gov/ftp/EMF/glcfs/gridded_fields/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set URL path to NOAA 'gridded fields' map files\n",
    "url_map = 'http://www.glerl.noaa.gov/ftp/EMF/glcfs/gridded_fields/map_files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# File types of interest [wave, wind, surface current, surface temperature]\n",
    "#extension_list = ['wav', 'wnd', 'cur', 'swt', 'ice', 'o', 'e', 's', 'm', 'h']\n",
    "extension_list = ['wav', 'wnd', 'cur', 'swt', 'ice', 'o']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define NOAA database class\n",
    "class NoaaDB:\n",
    "    \n",
    "    \"\"\"\n",
    "    Class: NoaaDB\n",
    "        - This class converts the NCAST|FCAST FTP database list into a pandas DataFrame\n",
    "        \n",
    "        - The gridded fields filename format is:\n",
    "\n",
    "          LYYYYDDDHH.N.EXT\n",
    "\n",
    "          L    = lake letter (s=Superior, m=Michigan, h=Huron, e=Erie, o=Ontario)\n",
    "          YYYY = year at start of simulation (GMT)\n",
    "          DDD  = Day Of Year at start of simulation (GMT)\n",
    "          HH   = hr at start of simulation (GMT)\n",
    "          N    = Site Number\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize object\n",
    "    def __init__(self, url, extension_list):\n",
    "        \n",
    "        # Set object attributes\n",
    "        self.url = url                            # FTP 'gridded data' database URL\n",
    "        self.url_ncast = self.url  + 'NCAST/'     # FTP NCAST database URL  \n",
    "        self.url_fcast = self.url  + 'FCAST/'     # FTP FCAST database URL   \n",
    "        self.extension_list = extension_list      # List of file type extensions   \n",
    "        self.html_ncast = {}                      # HTML from FCAST page\n",
    "        self.html_fcast = {}                      # HTML from FCAST page\n",
    "        self.html_obj_ncast = {}                  # FCAST HTML Object\n",
    "        self.html_obj_fcast = {}                  # FCAST HTML Object\n",
    "        \n",
    "        # Current UTC time as GMT\n",
    "        self.current_datetime_GMT = datetime.utcnow().replace(tzinfo=tz.gettz('GMT'))\n",
    "        \n",
    "        # Database dataframe\n",
    "        self.df = pd.DataFrame(index=[], columns=['filename', 'file_extension', \n",
    "                                                  'filetype', 'lake', 'file_datetime', \n",
    "                                                  'current_datetime','forecast_type', 'file_url'])                                       \n",
    "        \n",
    "    # Get NCAST database \n",
    "    def get_ncast(self):\n",
    "        \n",
    "        # Get DataFrame row count\n",
    "        df_rows = self.df.shape[0]-1\n",
    "        \n",
    "        # Get HTML from database page\n",
    "        self.html_ncast   = requests.get(self.url_ncast)\n",
    "        \n",
    "        # Create BeautifulSoup object\n",
    "        self.html_obj_ncast   = BeautifulSoup(self.html_ncast.content)\n",
    "        \n",
    "        # Set database list as dataframe \n",
    "        for link in self.html_obj_ncast.findAll('a', href=True):\n",
    "            if (\n",
    "                link.contents[0].split('.')[-1] in self.extension_list and \n",
    "                link.contents[0][0] in self.extension_list\n",
    "               ):\n",
    "                \n",
    "                df_rows += 1  # row count                                                 \n",
    "                \n",
    "                filename = link.contents[0]                                         # file name\n",
    "                file_extension = link.contents[0].split('.')[-1]                    # file extension\n",
    "                \n",
    "                # file datetime as GMT\n",
    "                file_datetime = datetime.strptime(link.contents[0].split('.')[0][1:len(link.contents[0].split('.')[0])], \"%Y%j%H\")       # file datetime (GMT)\n",
    "                file_datetime = file_datetime.replace(tzinfo=tz.gettz('GMT'))\n",
    "                \n",
    "                # Set file type\n",
    "                if file_extension == 'wav':           # Wave\n",
    "                    filetype = 'WAVES'\n",
    "                elif file_extension == 'wnd':         # Wind\n",
    "                    filetype = 'WINDS'\n",
    "                elif file_extension == 'cur':         # Surface Current\n",
    "                    filetype = 'SURFACE CURRENTS'\n",
    "                elif file_extension == 'swt':         # Surface Temperature\n",
    "                    filetype = 'SURFACE TEMPS'\n",
    "                elif file_extension == 'ice':         # Ice Conditions\n",
    "                    filetype = 'ICE PARAMS'\n",
    "                \n",
    "                # Set great lake\n",
    "                if filename[0] == 'e':       # Lake Erie\n",
    "                    lake = 'erie'\n",
    "                elif filename[0] == 'h':     # Lake Huron\n",
    "                    lake = 'huron'\n",
    "                elif filename[0] == 'o':     # Lake Ontario\n",
    "                    lake = 'ontario'\n",
    "                elif filename[0] == 's':     # Lake Superior\n",
    "                    lake = 'superior'\n",
    "                elif filename[0] == 'm':     # Lake Michigan\n",
    "                    lake = 'michigan'            \n",
    "                \n",
    "                # save to dataframe\n",
    "                self.df.loc[df_rows] = [filename, file_extension, filetype, \n",
    "                                        lake, file_datetime, self.current_datetime_GMT, \n",
    "                                        'NCAST', self.url_ncast]                                   \n",
    "                          \n",
    "    # Get FCAST database \n",
    "    def get_fcast(self):\n",
    "        \n",
    "        # Get DataFrame row count\n",
    "        df_rows = self.df.shape[0]-1\n",
    "        \n",
    "        # Get HTML from database page\n",
    "        self.html_fcast   = requests.get(self.url_fcast)\n",
    "        \n",
    "        # Create BeautifulSoup object\n",
    "        self.html_obj_fcast   = BeautifulSoup(self.html_fcast.content)\n",
    "        \n",
    "        # Set database list as dataframe \n",
    "        for link in self.html_obj_fcast.findAll('a', href=True):\n",
    "            if (\n",
    "                link.contents[0].split('.')[-1] in self.extension_list and \n",
    "                link.contents[0][0] in self.extension_list\n",
    "               ):\n",
    "                \n",
    "                df_rows += 1  # row count                                                 \n",
    "                \n",
    "                filename = link.contents[0]                                         # file name\n",
    "                file_extension = link.contents[0].split('.')[-1]                    # file extension\n",
    "                \n",
    "                # file datetime as GMT\n",
    "                file_datetime = datetime.strptime(link.contents[0].split('.')[0][1:len(link.contents[0].split('.')[0])], \"%Y%j%H\")       # file datetime (GMT)\n",
    "                file_datetime = file_datetime.replace(tzinfo=tz.gettz('GMT'))\n",
    "                \n",
    "                # Set file type\n",
    "                if file_extension == 'wav':           # Wave\n",
    "                    filetype = 'WAVES'\n",
    "                elif file_extension == 'wnd':         # Wind\n",
    "                    filetype = 'WINDS'\n",
    "                elif file_extension == 'cur':         # Surface Current\n",
    "                    filetype = 'SURFACE CURRENTS'\n",
    "                elif file_extension == 'swt':         # Surface Temperature\n",
    "                    filetype = 'SURFACE TEMPS'\n",
    "                elif file_extension == 'ice':         # Ice Conditions\n",
    "                    filetype = 'ICE PARAMS'\n",
    "                \n",
    "                # Set great lake\n",
    "                if filename[0] == 'e':       # Lake Erie\n",
    "                    lake = 'erie'\n",
    "                elif filename[0] == 'h':     # Lake Huron\n",
    "                    lake = 'huron'\n",
    "                elif filename[0] == 'o':     # Lake Ontario\n",
    "                    lake = 'ontario'\n",
    "                elif filename[0] == 's':     # Lake Superior\n",
    "                    lake = 'superior'\n",
    "                elif filename[0] == 'm':     # Lake Michigan\n",
    "                    lake = 'michigan'       \n",
    "                \n",
    "                # save to dataframe\n",
    "                self.df.loc[df_rows] = [filename, file_extension, filetype, \n",
    "                                        lake, file_datetime, self.current_datetime_GMT, \n",
    "                                        'FCAST', self.url_fcast]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create NoaaDB object\n",
    "noaa_files = NoaaDB(url, extension_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get NCAST files \n",
    "noaa_files.get_ncast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get FCAST files \n",
    "noaa_files.get_fcast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>file_extension</th>\n",
       "      <th>filetype</th>\n",
       "      <th>lake</th>\n",
       "      <th>file_datetime</th>\n",
       "      <th>current_datetime</th>\n",
       "      <th>forecast_type</th>\n",
       "      <th>file_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>o201611706.0.ice</td>\n",
       "      <td>ice</td>\n",
       "      <td>ICE PARAMS</td>\n",
       "      <td>ontario</td>\n",
       "      <td>2016-04-26 06:00:00</td>\n",
       "      <td>2016-05-28 16:33:26.739723</td>\n",
       "      <td>NCAST</td>\n",
       "      <td>http://www.glerl.noaa.gov/ftp/EMF/glcfs/gridde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>o201611712.0.ice</td>\n",
       "      <td>ice</td>\n",
       "      <td>ICE PARAMS</td>\n",
       "      <td>ontario</td>\n",
       "      <td>2016-04-26 12:00:00</td>\n",
       "      <td>2016-05-28 16:33:26.739723</td>\n",
       "      <td>NCAST</td>\n",
       "      <td>http://www.glerl.noaa.gov/ftp/EMF/glcfs/gridde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>o201611718.0.ice</td>\n",
       "      <td>ice</td>\n",
       "      <td>ICE PARAMS</td>\n",
       "      <td>ontario</td>\n",
       "      <td>2016-04-26 18:00:00</td>\n",
       "      <td>2016-05-28 16:33:26.739723</td>\n",
       "      <td>NCAST</td>\n",
       "      <td>http://www.glerl.noaa.gov/ftp/EMF/glcfs/gridde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>o201611800.0.ice</td>\n",
       "      <td>ice</td>\n",
       "      <td>ICE PARAMS</td>\n",
       "      <td>ontario</td>\n",
       "      <td>2016-04-27 00:00:00</td>\n",
       "      <td>2016-05-28 16:33:26.739723</td>\n",
       "      <td>NCAST</td>\n",
       "      <td>http://www.glerl.noaa.gov/ftp/EMF/glcfs/gridde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>o201611806.0.ice</td>\n",
       "      <td>ice</td>\n",
       "      <td>ICE PARAMS</td>\n",
       "      <td>ontario</td>\n",
       "      <td>2016-04-27 06:00:00</td>\n",
       "      <td>2016-05-28 16:33:26.739723</td>\n",
       "      <td>NCAST</td>\n",
       "      <td>http://www.glerl.noaa.gov/ftp/EMF/glcfs/gridde...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename file_extension    filetype     lake       file_datetime  \\\n",
       "0  o201611706.0.ice            ice  ICE PARAMS  ontario 2016-04-26 06:00:00   \n",
       "1  o201611712.0.ice            ice  ICE PARAMS  ontario 2016-04-26 12:00:00   \n",
       "2  o201611718.0.ice            ice  ICE PARAMS  ontario 2016-04-26 18:00:00   \n",
       "3  o201611800.0.ice            ice  ICE PARAMS  ontario 2016-04-27 00:00:00   \n",
       "4  o201611806.0.ice            ice  ICE PARAMS  ontario 2016-04-27 06:00:00   \n",
       "\n",
       "            current_datetime forecast_type  \\\n",
       "0 2016-05-28 16:33:26.739723         NCAST   \n",
       "1 2016-05-28 16:33:26.739723         NCAST   \n",
       "2 2016-05-28 16:33:26.739723         NCAST   \n",
       "3 2016-05-28 16:33:26.739723         NCAST   \n",
       "4 2016-05-28 16:33:26.739723         NCAST   \n",
       "\n",
       "                                            file_url  \n",
       "0  http://www.glerl.noaa.gov/ftp/EMF/glcfs/gridde...  \n",
       "1  http://www.glerl.noaa.gov/ftp/EMF/glcfs/gridde...  \n",
       "2  http://www.glerl.noaa.gov/ftp/EMF/glcfs/gridde...  \n",
       "3  http://www.glerl.noaa.gov/ftp/EMF/glcfs/gridde...  \n",
       "4  http://www.glerl.noaa.gov/ftp/EMF/glcfs/gridde...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show Dataframe of NoaaDB files \n",
    "noaa_files.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>file_extension</th>\n",
       "      <th>filetype</th>\n",
       "      <th>lake</th>\n",
       "      <th>file_datetime</th>\n",
       "      <th>current_datetime</th>\n",
       "      <th>forecast_type</th>\n",
       "      <th>file_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>o201614900.0.wnd</td>\n",
       "      <td>wnd</td>\n",
       "      <td>WINDS</td>\n",
       "      <td>ontario</td>\n",
       "      <td>2016-05-28 00:00:00</td>\n",
       "      <td>2016-05-28 16:33:26.739723</td>\n",
       "      <td>FCAST</td>\n",
       "      <td>http://www.glerl.noaa.gov/ftp/EMF/glcfs/gridde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>o201614912.0.cur</td>\n",
       "      <td>cur</td>\n",
       "      <td>SURFACE CURRENTS</td>\n",
       "      <td>ontario</td>\n",
       "      <td>2016-05-28 12:00:00</td>\n",
       "      <td>2016-05-28 16:33:26.739723</td>\n",
       "      <td>FCAST</td>\n",
       "      <td>http://www.glerl.noaa.gov/ftp/EMF/glcfs/gridde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>o201614912.0.swt</td>\n",
       "      <td>swt</td>\n",
       "      <td>SURFACE TEMPS</td>\n",
       "      <td>ontario</td>\n",
       "      <td>2016-05-28 12:00:00</td>\n",
       "      <td>2016-05-28 16:33:26.739723</td>\n",
       "      <td>FCAST</td>\n",
       "      <td>http://www.glerl.noaa.gov/ftp/EMF/glcfs/gridde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>o201614912.0.wav</td>\n",
       "      <td>wav</td>\n",
       "      <td>WAVES</td>\n",
       "      <td>ontario</td>\n",
       "      <td>2016-05-28 12:00:00</td>\n",
       "      <td>2016-05-28 16:33:26.739723</td>\n",
       "      <td>FCAST</td>\n",
       "      <td>http://www.glerl.noaa.gov/ftp/EMF/glcfs/gridde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>o201614912.0.wnd</td>\n",
       "      <td>wnd</td>\n",
       "      <td>WINDS</td>\n",
       "      <td>ontario</td>\n",
       "      <td>2016-05-28 12:00:00</td>\n",
       "      <td>2016-05-28 16:33:26.739723</td>\n",
       "      <td>FCAST</td>\n",
       "      <td>http://www.glerl.noaa.gov/ftp/EMF/glcfs/gridde...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             filename file_extension          filetype     lake  \\\n",
       "219  o201614900.0.wnd            wnd             WINDS  ontario   \n",
       "220  o201614912.0.cur            cur  SURFACE CURRENTS  ontario   \n",
       "221  o201614912.0.swt            swt     SURFACE TEMPS  ontario   \n",
       "222  o201614912.0.wav            wav             WAVES  ontario   \n",
       "223  o201614912.0.wnd            wnd             WINDS  ontario   \n",
       "\n",
       "          file_datetime           current_datetime forecast_type  \\\n",
       "219 2016-05-28 00:00:00 2016-05-28 16:33:26.739723         FCAST   \n",
       "220 2016-05-28 12:00:00 2016-05-28 16:33:26.739723         FCAST   \n",
       "221 2016-05-28 12:00:00 2016-05-28 16:33:26.739723         FCAST   \n",
       "222 2016-05-28 12:00:00 2016-05-28 16:33:26.739723         FCAST   \n",
       "223 2016-05-28 12:00:00 2016-05-28 16:33:26.739723         FCAST   \n",
       "\n",
       "                                              file_url  \n",
       "219  http://www.glerl.noaa.gov/ftp/EMF/glcfs/gridde...  \n",
       "220  http://www.glerl.noaa.gov/ftp/EMF/glcfs/gridde...  \n",
       "221  http://www.glerl.noaa.gov/ftp/EMF/glcfs/gridde...  \n",
       "222  http://www.glerl.noaa.gov/ftp/EMF/glcfs/gridde...  \n",
       "223  http://www.glerl.noaa.gov/ftp/EMF/glcfs/gridde...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show Dataframe of NoaaDB files \n",
    "noaa_files.df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Step 2</h1>\n",
    "<h3>Find Most Recently Uploaded Files</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define NOAA database file class\n",
    "class NoaaDB_NewestFile():\n",
    "    \n",
    "    \"\"\"\n",
    "    Class: NoaaDB_NewestFile\n",
    "        - This class Takes a lake and attribute as input and finds the most recently uploaded corresponding file. \n",
    "    \n",
    "    Inputs:\n",
    "            - lake:       Lake of interest [ontario, michigan, erie, superior, huron] \n",
    "            - attribute:  File extension [cur, swt, wav, wnd] \n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize object\n",
    "    def __init__(self, noaa_files, url_map):\n",
    "        \n",
    "        # Set object attributes\n",
    "        self.noaa_files = noaa_files              # user input NoaaDB object (Pandas Dataframe of all files in Noaa DB)\n",
    "        self.df_ncast = {}                        # downloaded NCAST text files as DataFrame\n",
    "        self.df_fcast = {}                        # downloaded FCAST text files as DataFrame\n",
    "        self.df_ncast_header = {}                 # NCAST text file headers\n",
    "        self.df_fcast_header = {}                 # FCAST text file headers\n",
    "        self.df = {}                              # conbined NCAST and FCAST DataFrames of most recent 120 hr forecast\n",
    "        self.url_map = url_map                    # url containing map files\n",
    "        \n",
    "        # Set map path\n",
    "        self.map_path = r'C:\\Users\\Sebastian\\Projects\\Websites\\Surfcast\\GetData\\GridFiles'\n",
    "        \n",
    "        # Get Newest NCAST Files in database and save as DataFrame\n",
    "        maxtime = noaa_files.df[(noaa_files.df.forecast_type == 'NCAST')]['file_datetime'].max()\n",
    "        self.newest_files_ncast = noaa_files.df[(noaa_files.df.forecast_type == 'NCAST') &\n",
    "                                                (noaa_files.df.file_datetime == maxtime)].reset_index(drop=True)\n",
    "        \n",
    "        # Get Newest FCAST Files in database and save as DataFrame\n",
    "        maxtime = noaa_files.df[(noaa_files.df.forecast_type == 'FCAST')]['file_datetime'].max()\n",
    "        self.newest_files_fcast = noaa_files.df[(noaa_files.df.forecast_type == 'FCAST') & \n",
    "                                                (noaa_files.df.file_datetime == maxtime)].reset_index(drop=True)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    # Find the number of grid points for a given file\n",
    "    def grid_count(self, row):\n",
    "\n",
    "        # Get first line in file\n",
    "        first_line = urlopen(row['file_url'] + row['filename']).readline()\n",
    "\n",
    "        # Get grid number from first line\n",
    "        grid_num = first_line.split()[-1].decode('ascii')\n",
    "\n",
    "        return grid_num\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Download newest file and save as row delimited list\n",
    "    def download_file(self, url, filename):\n",
    "\n",
    "        \"\"\"\n",
    "        Function: download_file\n",
    "            - This function will download from the NOAA database the text file corresponding to the filename\n",
    "              and url input by the user and return a row delimited text file.\n",
    "              \n",
    "        Inputs:\n",
    "            - filename:     Name of the file to download\n",
    "            - url:          Url of the file to download \n",
    "\n",
    "        Outputs:\n",
    "            - textfile:     The corresponding row delimited text file\n",
    "        \"\"\"           \n",
    "        \n",
    "        # Send file request to server and download\n",
    "        response = request.urlopen(url + filename)\n",
    "\n",
    "        # Parse text file by line breaks\n",
    "        textfile = str(response.read().decode('utf-8')).split('\\n')\n",
    "        \n",
    "        # return row delimited text file\n",
    "        return textfile\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Get the number of forecast hours per file\n",
    "    def hour_count(self, url, filename):\n",
    "\n",
    "        text_file = self.download_file(url, filename)\n",
    "\n",
    "        hours = 0    # number of data rows in text file\n",
    "        \n",
    "        # Loop through all rows in file\n",
    "        for row in text_file:\n",
    "            if 'dat' in row:\n",
    "                hours += 1  # hour count\n",
    "\n",
    "        # Return number of forecast hours          \n",
    "        return hours\n",
    "    \n",
    "    \n",
    "    def get_headers(self):\n",
    "        \n",
    "        # Define function to extract header information\n",
    "        def header_array(row):\n",
    "            if 'dat' in row and len(row.split()) != 0:\n",
    "                array = np.array(row.split()).astype(object)\n",
    "                return array\n",
    "            else: \n",
    "                return None\n",
    "            \n",
    "        header_array_vec = np.vectorize(header_array)  # Vecotize function\n",
    "        \n",
    "        # -------------------------------------------------------------------------------------------------------------------- #\n",
    "        # NCAST \n",
    "        # -------------------------------------------------------------------------------------------------------------------- #\n",
    "        \n",
    "        self.df_ncast_header = pd.DataFrame(index=[0], \n",
    "                                            columns=['year_start', 'day_start', 'hour_start', 'datetime_start', 'skip_start', \n",
    "                                                     'year_end', 'day_end', 'hour_end', 'datetime_end', 'skip_end', \n",
    "                                                     'grid_count', 'forecast_hours', 'data_rows',  \n",
    "                                                     'lake', 'filetype'])\n",
    "\n",
    "        # Write NCAST data to DataFrame\n",
    "        row_count = 0\n",
    "        for lake in self.newest_files_ncast.lake.unique():\n",
    "            \n",
    "            df_lake = self.newest_files_ncast[(self.newest_files_ncast.lake == lake)]\n",
    "\n",
    "            for df_index in df_lake.index:\n",
    "                \n",
    "                # Download text file\n",
    "                text_file = self.download_file(self.newest_files_ncast.file_url[df_index], \n",
    "                                               self.newest_files_ncast.filename[df_index])\n",
    "                \n",
    "                text_header = header_array_vec(text_file)\n",
    "                text_header = text_header[text_header != np.array(None)]\n",
    "                text_header = np.vstack(text_header)\n",
    "                \n",
    "                self.df_ncast_header.loc[row_count, ['year_start', 'day_start', 'hour_start']] = text_header[0, 0:3]\n",
    "                file_datetime = datetime.strptime(self.df_ncast_header.year_start[row_count] + \n",
    "                                                  self.df_ncast_header.day_start[row_count] + \n",
    "                                                  self.df_ncast_header.hour_start[row_count], \"%Y%j%H\")       \n",
    "                self.df_ncast_header.loc[row_count, ['datetime_start']] = file_datetime\n",
    "                \n",
    "                self.df_ncast_header.loc[row_count, ['year_end', 'day_end', 'hour_end']] = text_header[-1, 0:3]\n",
    "                file_datetime = datetime.strptime(self.df_ncast_header.year_end[row_count] + \n",
    "                                                  self.df_ncast_header.day_end[row_count] + \n",
    "                                                  self.df_ncast_header.hour_end[row_count], \"%Y%j%H\")       \n",
    "                self.df_ncast_header.loc[row_count, ['datetime_end']] = file_datetime\n",
    "                \n",
    "                self.df_ncast_header.loc[row_count, ['grid_count']] = int(text_header[0, -1])\n",
    "                self.df_ncast_header.loc[row_count, ['forecast_hours']] = int(text_header.shape[0])\n",
    "                self.df_ncast_header.loc[row_count, ['data_rows']] = self.df_ncast_header.grid_count[row_count] * \\\n",
    "                                                                     self.df_ncast_header.forecast_hours[row_count]\n",
    "                self.df_ncast_header.loc[row_count, ['lake']] = self.newest_files_ncast.lake[df_index]\n",
    "                self.df_ncast_header.loc[row_count, ['filetype']] = self.newest_files_ncast.filetype[df_index]\n",
    "                \n",
    "                row_count += 1 \n",
    "                \n",
    "        # -------------------------------------------------------------------------------------------------------------------- #\n",
    "        # FCAST \n",
    "        # -------------------------------------------------------------------------------------------------------------------- #\n",
    "        \n",
    "        self.df_fcast_header = pd.DataFrame(index=[0], \n",
    "                                            columns=['year_start', 'day_start', 'hour_start', 'datetime_start', 'skip_start', \n",
    "                                                     'year_end', 'day_end', 'hour_end', 'datetime_end', 'skip_end', \n",
    "                                                     'grid_count', 'forecast_hours', 'data_rows',  \n",
    "                                                     'lake', 'filetype'])\n",
    "\n",
    "        # Write FCAST data to DataFrame\n",
    "        row_count = 0\n",
    "        for lake in self.newest_files_fcast.lake.unique():\n",
    "            \n",
    "            df_lake = self.newest_files_fcast[(self.newest_files_fcast.lake == lake)]\n",
    "\n",
    "            for df_index in df_lake.index:\n",
    "                \n",
    "                # Download text file\n",
    "                text_file = self.download_file(self.newest_files_fcast.file_url[df_index], \n",
    "                                               self.newest_files_fcast.filename[df_index])\n",
    "                \n",
    "                text_header = header_array_vec(text_file)\n",
    "                text_header = text_header[text_header != np.array(None)]\n",
    "                text_header = np.vstack(text_header)\n",
    "                \n",
    "                self.df_fcast_header.loc[row_count, ['year_start', 'day_start', 'hour_start']] = text_header[0, 0:3]\n",
    "                file_datetime = datetime.strptime(self.df_fcast_header.year_start[row_count] + \n",
    "                                                  self.df_fcast_header.day_start[row_count] + \n",
    "                                                  self.df_fcast_header.hour_start[row_count], \"%Y%j%H\")       \n",
    "                self.df_fcast_header.loc[row_count, ['datetime_start']] = file_datetime\n",
    "                \n",
    "                self.df_fcast_header.loc[row_count, ['year_end', 'day_end', 'hour_end']] = text_header[-1, 0:3]\n",
    "                file_datetime = datetime.strptime(self.df_fcast_header.year_end[row_count] + \n",
    "                                                  self.df_fcast_header.day_end[row_count] + \n",
    "                                                  self.df_fcast_header.hour_end[row_count], \"%Y%j%H\")       \n",
    "                self.df_fcast_header.loc[row_count, ['datetime_end']] = file_datetime\n",
    "                \n",
    "                self.df_fcast_header.loc[row_count, ['grid_count']] = int(text_header[0, -1])\n",
    "                self.df_fcast_header.loc[row_count, ['forecast_hours']] = int(text_header.shape[0])\n",
    "                self.df_fcast_header.loc[row_count, ['data_rows']] = self.df_fcast_header.grid_count[row_count] * \\\n",
    "                                                                     self.df_fcast_header.forecast_hours[row_count]\n",
    "                self.df_fcast_header.loc[row_count, ['lake']] = self.newest_files_fcast.lake[df_index]\n",
    "                self.df_fcast_header.loc[row_count, ['filetype']] = self.newest_files_fcast.filetype[df_index]\n",
    "                \n",
    "                row_count += 1 \n",
    "\n",
    "    # Add grid information to newest_files_ncast and newest_files_fcast\n",
    "    def add_grid_data(self):\n",
    "        \n",
    "        # -------------------------------------------------------------------------------------------------------------------- #\n",
    "        # NCAST \n",
    "        # -------------------------------------------------------------------------------------------------------------------- #\n",
    "        \n",
    "        # Get number of grid points for each file\n",
    "        self.newest_files_ncast['grid_count'] = pd.Series(index=self.newest_files_ncast.index)\n",
    "        self.newest_files_ncast['grid_count'] = self.newest_files_ncast.apply(self.grid_count, axis=1).astype(int)\n",
    "        \n",
    "        # Get hours per file\n",
    "        hours_ncast = self.hour_count(self.newest_files_ncast.file_url[0], \n",
    "                                      self.newest_files_ncast.filename[0])\n",
    "        \n",
    "        self.newest_files_ncast['forecast_hours'] = pd.Series(index=self.newest_files_ncast.index)  \n",
    "        self.newest_files_ncast['forecast_hours'] = hours_ncast                                  \n",
    "        \n",
    "        # Set data rows\n",
    "        self.newest_files_ncast['data_rows'] = pd.Series(index=self.newest_files_ncast.index)\n",
    "        self.newest_files_ncast['data_rows'] = self.newest_files_ncast['grid_count'] * \\\n",
    "                                               self.newest_files_ncast['forecast_hours']     \n",
    "        \n",
    "        # -------------------------------------------------------------------------------------------------------------------- #\n",
    "        # FCAST \n",
    "        # -------------------------------------------------------------------------------------------------------------------- #\n",
    "\n",
    "        # Get number of grid points for each file\n",
    "        self.newest_files_fcast['grid_count'] = pd.Series(index=self.newest_files_fcast.index)\n",
    "        self.newest_files_fcast['grid_count'] = self.newest_files_fcast.apply(self.grid_count, axis=1).astype(int) \n",
    "\n",
    "        # Get hours per file\n",
    "        hours_fcast = self.hour_count(self.newest_files_fcast.file_url[0], \n",
    "                                      self.newest_files_fcast.filename[0])\n",
    "        \n",
    "        self.newest_files_fcast['forecast_hours'] = pd.Series(index=self.newest_files_fcast.index)  \n",
    "        self.newest_files_fcast['forecast_hours'] = hours_fcast                                    \n",
    "\n",
    "        # Set data rows\n",
    "        self.newest_files_fcast['data_rows'] = pd.Series(index=self.newest_files_fcast.index)\n",
    "        self.newest_files_fcast['data_rows'] = self.newest_files_fcast['grid_count'] * \\\n",
    "                                               self.newest_files_fcast['forecast_hours']     \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    # Set up empty DataFrames to hold text file data\n",
    "    def df_setup(self):\n",
    "        \n",
    "        # -------------------------------------------------------------------------------------------------------------------- #\n",
    "        # NCAST \n",
    "        # -------------------------------------------------------------------------------------------------------------------- #\n",
    "        \n",
    "        # Get number of NCAST rows\n",
    "        row_num = self.newest_files_ncast.data_rows.unique().sum()\n",
    "\n",
    "        # NOAA attributes\n",
    "        wave =        ['wave_height', 'wave_direction', 'wave_period']\n",
    "        wind =        ['wind_speed', 'wind_direction']\n",
    "        temperature = ['surface_temperature']\n",
    "        current =     ['currect_speed', 'current_direction']\n",
    "        ice =         ['ice_concentration', 'ice_thickness', 'ice_speed', 'ice_direction']\n",
    "        \n",
    "        # Get list of unique NCAST file types and lakes\n",
    "        filetype_ncast = self.newest_files_ncast.filetype.unique()\n",
    "        \n",
    "        # Setup NCAST DataFrame\n",
    "        self.df_ncast  = pd.DataFrame(index=range(row_num), \n",
    "                                      columns=['year', 'day', 'hour', 'datetime',                       # datetime \n",
    "                                               'grid_number', 'latitude', 'longitude', 'map', 'lake'])  # grid    \n",
    "        \n",
    "        if any('WAVES' in s for s in filetype_ncast):               # wave\n",
    "            for col in wave:\n",
    "                self.df_ncast[col] = pd.Series(index=self.df_ncast.index) \n",
    "                \n",
    "        if any('WINDS' in s for s in filetype_ncast):               # wind              \n",
    "            for col in wind:\n",
    "                self.df_ncast[col] = pd.Series(index=self.df_ncast.index)\n",
    "                \n",
    "        if any('SURFACE TEMPS' in s for s in filetype_ncast):       # temperature\n",
    "            for col in temperature:\n",
    "                self.df_ncast[col] = pd.Series(index=self.df_ncast.index)\n",
    "                \n",
    "        if any('SURFACE CURRENTS' in s for s in filetype_ncast):    # current\n",
    "            for col in current:\n",
    "                self.df_ncast[col] = pd.Series(index=self.df_ncast.index)\n",
    "                \n",
    "        if any('ICE PARAMS' in s for s in filetype_ncast):          # ice\n",
    "            for col in ice:\n",
    "                self.df_ncast[col] = pd.Series(index=self.df_ncast.index)\n",
    "        \n",
    "        # -------------------------------------------------------------------------------------------------------------------- #\n",
    "        # FCAST \n",
    "        # -------------------------------------------------------------------------------------------------------------------- #\n",
    "        \n",
    "        # Get number of NCAST rows\n",
    "        row_num = self.newest_files_fcast.data_rows.unique().sum()\n",
    "\n",
    "        # NOAA attributes\n",
    "        wave =        ['wave_height', 'wave_direction', 'wave_period']\n",
    "        wind =        ['wind_speed', 'wind_direction']\n",
    "        temperature = ['surface_temperature']\n",
    "        current =     ['currect_speed', 'current_direction']\n",
    "        ice =         ['ice_concentration', 'ice_thickness', 'ice_speed', 'ice_direction']\n",
    "        \n",
    "        # Get list of unique NCAST file types and lakes\n",
    "        filetype_fcast = self.newest_files_fcast.filetype.unique()\n",
    "\n",
    "        # Setup NCAST DataFrame\n",
    "        self.df_fcast  = pd.DataFrame(index=range(row_num), \n",
    "                                      columns=['year', 'day', 'hour', 'datetime',                       # datetime \n",
    "                                               'grid_number', 'latitude', 'longitude', 'map', 'lake'])  # grid    \n",
    "        \n",
    "        if any('WAVES' in s for s in filetype_fcast):                         # wave\n",
    "            for col in wave:\n",
    "                self.df_fcast[col] = pd.Series(index=self.df_fcast.index) \n",
    "                \n",
    "        if any('WINDS' in s for s in filetype_fcast):                         # wind              \n",
    "            for col in wind:\n",
    "                self.df_fcast[col] = pd.Series(index=self.df_fcast.index)\n",
    "                \n",
    "        if any('SURFACE TEMPS' in s for s in filetype_fcast):                 # temperature\n",
    "            for col in temperature:\n",
    "                self.df_fcast[col] = pd.Series(index=self.df_fcast.index)\n",
    "                \n",
    "        if any('SURFACE CURRENTS' in s for s in filetype_fcast):              # current\n",
    "            for col in current:\n",
    "                self.df_fcast[col] = pd.Series(index=self.df_fcast.index)\n",
    "                \n",
    "        if any('ICE PARAMS' in s for s in filetype_fcast):                    # ice\n",
    "            for col in ice:\n",
    "                self.df_fcast[col] = pd.Series(index=self.df_fcast.index)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "    # Fill NCAST and FCAST DataFrames with text file data\n",
    "    def df_fill(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        The gridded fields data format is:\n",
    "\n",
    "          col_1 = grid number corresponding to a grid file\n",
    "        \n",
    "        For Wind Speed:\n",
    "          col_2 = 10m wind speed at grid center (m/s)\n",
    "          col_3 = wind direction at grid center (0 = from north, 90 = from east)\n",
    "\n",
    "        For Surface Currents:\n",
    "          col_2 = surface current speed at grid center (m/s)\n",
    "          col_3 = surface current direction at grid center (0 = toward north, 90 = toward east)\n",
    "\n",
    "        For Waves:\n",
    "          col_2 = significant wave height at grid center (m)\n",
    "          col_3 = significant wave direction at grid center (0 = toward north, 90 = toward east)\n",
    "          col_4 = significant wave period (s)\n",
    "\n",
    "        For Surface Water Temps:\n",
    "          col_2 = surface water temperature (C) at grid center\n",
    "\n",
    "        For Ice Model results:\n",
    "          col_2 = ice concentration (0-1) at grid centerwww.f\n",
    "          col_3 = ice thickness (m) at grid center\n",
    "          col_4 = ice speed (m/s) at grid cente\n",
    "          col_5 = ice direction (m/s) at grid center\n",
    "        \"\"\"\n",
    "\n",
    "        # Define function to parse text file rows and identify headers\n",
    "        def data_array(row):\n",
    "            if 'dat' not in row and len(row.split()) != 0:\n",
    "                array = np.array(row.split()).astype(float)\n",
    "                return array\n",
    "            else: \n",
    "                return None\n",
    "            \n",
    "        data_array_vec = np.vectorize(data_array)  # Vecotize function\n",
    "        \n",
    "        # Define function to extract header information\n",
    "        def header_array(row):\n",
    "            if 'dat' in row and len(row.split()) != 0:\n",
    "                array = np.array(row.split()).astype(object)\n",
    "                return array\n",
    "            else: \n",
    "                return None\n",
    "            \n",
    "        header_array_vec = np.vectorize(header_array)  # Vecotize function\n",
    "        \n",
    "        # NOAA attributes\n",
    "        wave =        ['grid_number', 'wave_height', 'wave_direction', 'wave_period']\n",
    "        wind =        ['grid_number', 'wind_speed', 'wind_direction']\n",
    "        temperature = ['grid_number', 'surface_temperature']\n",
    "        current =     ['grid_number', 'currect_speed', 'current_direction']\n",
    "        ice =         ['grid_number', 'ice_concentration', 'ice_thickness', 'ice_speed', 'ice_direction']\n",
    "        \n",
    "        # -------------------------------------------------------------------------------------------------------------------- #\n",
    "        # NCAST \n",
    "        # -------------------------------------------------------------------------------------------------------------------- #\n",
    "        \n",
    "        # Write NCAST data to DataFrame\n",
    "        row_count = 0\n",
    "        for lake in self.newest_files_ncast.lake.unique():\n",
    "            \n",
    "            df_lake = self.newest_files_ncast[(self.newest_files_ncast.lake == lake)]\n",
    "\n",
    "            for df_index in df_lake.index:\n",
    "                \n",
    "                # Set attributes to set based on filetype\n",
    "                if  self.newest_files_ncast.filetype[df_index] == 'WAVES':\n",
    "                    cols = wave\n",
    "                elif self.newest_files_ncast.filetype[df_index] == 'WINDS':\n",
    "                    cols = wind\n",
    "                elif self.newest_files_ncast.filetype[df_index] == 'SURFACE TEMPS':\n",
    "                    cols = temperature\n",
    "                elif self.newest_files_ncast.filetype[df_index] == 'SURFACE CURRENTS':\n",
    "                    cols = current\n",
    "                elif self.newest_files_ncast.filetype[df_index] == 'ICE PARAMS':\n",
    "                    cols = ice   \n",
    "                \n",
    "                # Download text file\n",
    "                text_file = self.download_file(self.newest_files_ncast.file_url[df_index], \n",
    "                                               self.newest_files_ncast.filename[df_index])\n",
    "                \n",
    "                # Get map from header\n",
    "                map = text_file[0].split()[3].split('/')[-1]\n",
    "                map = map.split('.')[0] + '.' + 'map'\n",
    "                if lake == 'superior':\n",
    "                    map = 'superior' + map.split('sup')[1]\n",
    "                \n",
    "                # Format text file data as numpy array\n",
    "                text_data = data_array_vec(text_file)                      # parse rows\n",
    "                text_data = text_data[text_data != np.array(None)]         # remove headers\n",
    "                text_data = np.vstack(text_data)\n",
    "                \n",
    "                # Format text file header data as numpy array\n",
    "                text_header = header_array_vec(text_file)\n",
    "                text_header = text_header[text_header != np.array(None)]\n",
    "                text_header = np.vstack(text_header)\n",
    "                \n",
    "                print('')\n",
    "                print('NCAST HEADER')\n",
    "                print(text_header)\n",
    "                print('')\n",
    "\n",
    "                # Create empty arrays for time (y, d, r) and datetime (GMT)\n",
    "                time_count = np.zeros([self.newest_files_ncast.data_rows[df_index] ,3]).astype(int)\n",
    "                date_time = np.zeros([self.newest_files_ncast.data_rows[df_index] ,1]).astype(object)\n",
    "                \n",
    "                # set row count\n",
    "                count = 0 \n",
    "                \n",
    "                # Loop thought text file headers\n",
    "                for header in text_header:\n",
    "                    \n",
    "                    # Set year, day, hour\n",
    "                    time_count[count:count + self.newest_files_ncast.grid_count[df_index], 0] = header[0]\n",
    "                    time_count[count:count + self.newest_files_ncast.grid_count[df_index], 1] = header[1]\n",
    "                    time_count[count:count + self.newest_files_ncast.grid_count[df_index], 2] = header[2]\n",
    "                    \n",
    "                    # Set date time object (GMT)\n",
    "                    date_time[count:count + self.newest_files_ncast.grid_count[df_index], 0] = datetime.strptime(header[0] + header[1] + header[2], \"%Y%j%H\") \n",
    "                    \n",
    "                    # Update count\n",
    "                    count = count + self.newest_files_ncast.grid_count[df_index]\n",
    "          \n",
    "                # Set text file data as DataFrame\n",
    "                self.df_ncast.loc[row_count:row_count + self.newest_files_ncast.data_rows[df_index]-1, cols] = text_data\n",
    "                \n",
    "                # Set header year, day, hour\n",
    "                self.df_ncast.loc[row_count:row_count + self.newest_files_ncast.data_rows[df_index]-1, 'year'] = time_count[:, 0]\n",
    "                self.df_ncast.loc[row_count:row_count + self.newest_files_ncast.data_rows[df_index]-1, 'day'] = time_count[:, 1]\n",
    "                self.df_ncast.loc[row_count:row_count + self.newest_files_ncast.data_rows[df_index]-1, 'hour'] = time_count[:, 2]\n",
    "                \n",
    "                # Set date time object (GMT)\n",
    "                self.df_ncast.loc[row_count:row_count + self.newest_files_ncast.data_rows[df_index]-1, 'datetime'] = date_time\n",
    "                \n",
    "                # Set static values\n",
    "                self.df_ncast.loc[row_count:row_count + self.newest_files_ncast.data_rows[df_index]-1, 'map'] = map    # map\n",
    "                self.df_ncast.loc[row_count:row_count + self.newest_files_ncast.data_rows[df_index]-1, 'lake'] = lake  # lake\n",
    "                \n",
    "                # Get map grid data\n",
    "                map_file = self.download_file(url_map, map)\n",
    "                map_data = np.loadtxt(map_file)\n",
    "                map_data = np.tile(map_data, (self.newest_files_ncast.forecast_hours[df_index], 1))\n",
    "                \n",
    "                # Set map grid data\n",
    "                self.df_ncast.loc[row_count:row_count + self.newest_files_ncast.data_rows[df_index]-1, \n",
    "                                  'latitude'] = time_count[:, 0] = map_data[:, 3]\n",
    "                self.df_ncast.loc[row_count:row_count + self.newest_files_ncast.data_rows[df_index]-1, \n",
    "                                  'longitude'] = time_count[:, 0] = map_data[:, 4]\n",
    "\n",
    "            # Row count update for new lake\n",
    "            row_count = row_count + self.newest_files_ncast.data_rows[df_index]     \n",
    "            \n",
    "        # -------------------------------------------------------------------------------------------------------------------- #\n",
    "        # FCAST \n",
    "        # -------------------------------------------------------------------------------------------------------------------- #\n",
    "        \n",
    "        # Write fcast data to DataFrame\n",
    "        row_count = 0\n",
    "        for lake in self.newest_files_fcast.lake.unique():\n",
    "\n",
    "            df_lake = self.newest_files_fcast[(self.newest_files_fcast.lake == lake)]\n",
    "\n",
    "            for df_index in df_lake.index:\n",
    "\n",
    "                # Set attributes to set based on filetype\n",
    "                if  self.newest_files_fcast.filetype[df_index] == 'WAVES':\n",
    "                    cols = wave\n",
    "                elif self.newest_files_fcast.filetype[df_index] == 'WINDS':\n",
    "                    cols = wind\n",
    "                elif self.newest_files_fcast.filetype[df_index] == 'SURFACE TEMPS':\n",
    "                    cols = temperature\n",
    "                elif self.newest_files_fcast.filetype[df_index] == 'SURFACE CURRENTS':\n",
    "                    cols = current\n",
    "                elif self.newest_files_fcast.filetype[df_index] == 'ICE PARAMS':\n",
    "                    cols = ice   \n",
    "\n",
    "                # Download text file\n",
    "                text_file = self.download_file(self.newest_files_fcast.file_url[df_index], \n",
    "                                               self.newest_files_fcast.filename[df_index])\n",
    "\n",
    "                # Get map from header\n",
    "                map = text_file[0].split()[3].split('/')[-1]  \n",
    "                map = map.split('.')[0] + '.' + 'map'\n",
    "                if lake == 'superior':\n",
    "                    map = 'superior' + map.split('sup')[1]\n",
    "\n",
    "                # Format text file data as numpy array\n",
    "                text_data = data_array_vec(text_file)                      # parse rows\n",
    "                text_data = text_data[text_data != np.array(None)]         # remove headers\n",
    "                text_data = np.vstack(text_data)\n",
    "\n",
    "                # Format text file header data as numpy array\n",
    "                text_header = header_array_vec(text_file)\n",
    "                text_header = text_header[text_header != np.array(None)]\n",
    "                text_header = np.vstack(text_header)\n",
    "                \n",
    "                print('')\n",
    "                print('FCAST HEADER')\n",
    "                print(text_header)\n",
    "                print('')\n",
    "                \n",
    "                # Create empty arrays for time (y, d, r) and datetime (GMT)\n",
    "                time_count = np.zeros([self.newest_files_fcast.data_rows[df_index] ,3]).astype(int)\n",
    "                date_time = np.zeros([self.newest_files_fcast.data_rows[df_index] ,1]).astype(object)\n",
    "                \n",
    "                # set row count\n",
    "                count = 0 \n",
    "\n",
    "                # Loop thought text file headers\n",
    "                for header in text_header:\n",
    "\n",
    "                    # Set year, day, hour\n",
    "                    time_count[count:count + self.newest_files_fcast.grid_count[df_index], 0] = header[0]\n",
    "                    time_count[count:count + self.newest_files_fcast.grid_count[df_index], 1] = header[1]\n",
    "                    time_count[count:count + self.newest_files_fcast.grid_count[df_index], 2] = header[2]\n",
    "\n",
    "                    # Set date time object (GMT)\n",
    "                    date_time[count:count + self.newest_files_fcast.grid_count[df_index], 0] = datetime.strptime(header[0] + header[1] + header[2], \"%Y%j%H\") \n",
    "\n",
    "                    # Update count\n",
    "                    count = count + self.newest_files_fcast.grid_count[df_index]\n",
    "\n",
    "                # Set text file data as DataFrame\n",
    "                self.df_fcast.loc[row_count:row_count + self.newest_files_fcast.data_rows[df_index]-1, cols] = text_data\n",
    "\n",
    "                # Set header year, day, hour\n",
    "                self.df_fcast.loc[row_count:row_count + self.newest_files_fcast.data_rows[df_index]-1, 'year'] = time_count[:, 0]\n",
    "                self.df_fcast.loc[row_count:row_count + self.newest_files_fcast.data_rows[df_index]-1, 'day'] = time_count[:, 1]\n",
    "                self.df_fcast.loc[row_count:row_count + self.newest_files_fcast.data_rows[df_index]-1, 'hour'] = time_count[:, 2]\n",
    "                \n",
    "                # Set date time object (GMT)\n",
    "                self.df_fcast.loc[row_count:row_count + self.newest_files_fcast.data_rows[df_index]-1, 'datetime'] = date_time\n",
    "\n",
    "                # Set static values\n",
    "                self.df_fcast.loc[row_count:row_count + self.newest_files_fcast.data_rows[df_index]-1, 'map'] = map    # map\n",
    "                self.df_fcast.loc[row_count:row_count + self.newest_files_fcast.data_rows[df_index]-1, 'lake'] = lake  # lake\n",
    "\n",
    "                # Get map grid data\n",
    "                map_file = self.download_file(url_map, map)\n",
    "                map_data = np.loadtxt(map_file)\n",
    "                map_data = np.tile(map_data, (self.newest_files_fcast.forecast_hours[df_index], 1))\n",
    "                \n",
    "                # Set map grid data\n",
    "                self.df_fcast.loc[row_count:row_count + self.newest_files_fcast.data_rows[df_index]-1, \n",
    "                                  'latitude'] = time_count[:, 0] = map_data[:, 3]\n",
    "                self.df_fcast.loc[row_count:row_count + self.newest_files_fcast.data_rows[df_index]-1, \n",
    "                                  'longitude'] = time_count[:, 0] = map_data[:, 4]\n",
    "\n",
    "            # Row count update for new lake\n",
    "            row_count = row_count + self.newest_files_fcast.data_rows[df_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get all newest files\n",
    "newest_files = NoaaDB_NewestFile(noaa_files, url_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add grid data to newest files DataFrames\n",
    "newest_files.add_grid_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show newest NCAST files\n",
    "newest_files.newest_files_ncast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show newest FCAST files\n",
    "newest_files.newest_files_fcast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newest_files.get_headers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newest_files.df_ncast_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newest_files.df_fcast_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newest_files.df_ncast_header.grid_count[0]*newest_files.df_ncast_header.grid_count[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Step 3</h1>\n",
    "<h3>Save Data From Newest Files As DataFrame</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup NCAST and FCAST data DataFrames\n",
    "newest_files.df_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show NCAST data DataFrame\n",
    "newest_files.df_ncast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show FCAST data DataFrame\n",
    "newest_files.df_fcast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill DataFrames with text file data\n",
    "newest_files.df_fill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show NCAST data DataFrame\n",
    "newest_files.df_ncast.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show FCAST data DataFrame\n",
    "newest_files.df_fcast.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Step 4</h1>\n",
    "<h3>Load Surf Spots</h3>\n",
    "<h5>Thanks Grif!</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set surf spots file path and file name\n",
    "path = r'C:\\Users\\Sebastian\\Projects\\Websites\\Surfcast\\GetData\\SurfSpots'\n",
    "file = 'SurfSpots.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load surf spot data as DataFrame\n",
    "surf_spots = pd.read_csv(os.path.join(path, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show surf spot data\n",
    "surf_spots.sort('lake')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Step 5</h1>\n",
    "<h3>Plot Raw Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot grid points\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for lake in newest_files.df_ncast.lake.unique():\n",
    "    \n",
    "    df = newest_files.df_ncast[(newest_files.df_ncast.lake == lake) & \n",
    "                               (newest_files.df_ncast.datetime == newest_files.df_ncast.datetime.unique()[0])] \n",
    "    \n",
    "    plt.plot(-df.longitude, df.latitude, marker='.', linestyle='none', ms=2)\n",
    "\n",
    "plt.plot(surf_spots.longitude, surf_spots.latitude, color='k', marker='o', linestyle='none', ms=5)    \n",
    "    \n",
    "plt.tick_params(labelsize=14)\n",
    "\n",
    "plt.xlabel('Longitude', fontsize=20)\n",
    "plt.ylabel('Latitude', fontsize=20)\n",
    "\n",
    "plt.grid('on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot grid points as 3D scatter\n",
    "attribute = 'wave_height'\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "    \n",
    "df = newest_files.df_ncast[(newest_files.df_ncast.datetime == newest_files.df_ncast.datetime.unique()[0])] \n",
    "\n",
    "sc = plt.scatter(-df.longitude, df.latitude, c = df[attribute], edgecolors='none')\n",
    "\n",
    "cb = plt.colorbar(sc)\n",
    "cb.set_label(attribute.replace('_', ' ').title(), fontsize=20)\n",
    "plt.tick_params(labelsize=14)\n",
    "\n",
    "plt.xlabel('Longitude', fontsize=20)\n",
    "plt.ylabel('Latitude', fontsize=20)\n",
    "\n",
    "plt.grid('on')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Step 6</h1>\n",
    "<h3>Create SQL Database</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initializes database with filename 311_8M.db in current directory\n",
    "surfcast_sql_db = create_engine(r'sqlite:///C:\\Users\\Sebastian\\Projects\\Websites\\Surfcast\\GetData\\Surfcast.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Step 7</h1>\n",
    "<h3>Update SQL Database</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noaa_files.df.to_sql('data', surfcast_sql_db, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_query('SELECT lake FROM data', surfcast_sql_db)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1900-1254.71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
